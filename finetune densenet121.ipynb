{"cells":[{"metadata":{"trusted":true,"_uuid":"c8c48321b5d5023ea7072350d2c27854178e54c2"},"cell_type":"code","source":"import os\nfrom PIL import Image\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.models as models\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nclass MyDataset(Dataset):\n    def __init__(self, csv_path, data_dir = './', transform=None):\n        super().__init__()\n        self.df = pd.read_csv(csv_path).values\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_name, label = self.df[index]\n        img_path = os.path.join(self.data_dir, img_name)\n        with Image.open(img_path) as img:\n            image = img.convert('RGB')\n        if self.transform is not None:\n            image = self.transform(image)\n        return image, label-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7540ef5616442308c6b59046586f536e92562e16"},"cell_type":"code","source":"use_gpu = True\nnum_classes = 5\nnum_epochs = 200\nearly_stopping = 10\nmodel = models.densenet201(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ee665ba458e254bea650a74a6dbbe91333206481"},"cell_type":"code","source":"for para in list(model.parameters()):\n    para.requires_grad=False\nfor para in list(model.features.denseblock3.parameters()):\n    para.requires_grad=True\nfor para in list(model.features.transition3.parameters()):\n    para.requires_grad=True\nfor para in list(model.features.denseblock4.parameters()):\n    para.requires_grad=True\nfor para in list(model.features.norm5.parameters()):\n    para.requires_grad=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"afd0fdc3fd57ed3e85c2ead27a986dc6ec6e547d"},"cell_type":"code","source":"model.classifier = nn.Sequential(\n    nn.Dropout(0.2),\n    nn.Linear(1920, num_classes),\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"13838c7b29be5aefaac54ba4625a28694f6ab2f8"},"cell_type":"code","source":"if use_gpu:\n    model = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ee2389530c7098dcc283328d1862919ef97c84f","scrolled":true},"cell_type":"code","source":"df = pd.read_csv('../input/train/train.csv')\ndf.sort_values('filename',inplace=True)\ndf_train, df_valid = train_test_split(df, test_size=0.2, stratify=df[' type'].values, shuffle=True, \n                                     random_state=1234)\ndf_train.to_csv('df_train.csv',index=False)\ndf_valid.to_csv('df_valid.csv',index=False)\n\ntrans_train = transforms.Compose([transforms.RandomResizedCrop(size=224),\n                            transforms.RandomHorizontalFlip(),\n#                             transforms.ColorJitter(0.5,0, 0.5,0),\n                            transforms.RandomGrayscale(),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])])\n\ntrans_valid = transforms.Compose([transforms.Resize(size=256),\n                            transforms.CenterCrop(size=224),\n                            transforms.ToTensor(),\n                            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])])\n\ndataset_train = MyDataset(csv_path='df_train.csv', \n    data_dir='../input/train/data/', transform=trans_train)\ndataset_valid = MyDataset(csv_path='df_valid.csv', \n    data_dir='../input/train/data/', transform=trans_valid)\n\nloader_train = DataLoader(dataset = dataset_train, batch_size=32, shuffle=True, num_workers=0)\nloader_valid = DataLoader(dataset = dataset_valid, batch_size=32, shuffle=False, num_workers=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c53cece343df41cfbe044eb479f006e3d1080b47"},"cell_type":"code","source":"params_to_update = []\nfor name,param in model.named_parameters():\n    if param.requires_grad == True:\n        params_to_update.append(param)\n        print(\"\\t\",name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad7777016439f4a2ba10541e629b290d991903b4"},"cell_type":"code","source":"# classifer_params_id = list(map(id, model.classifier.parameters()))\n# conv_params = filter(lambda p: id(p) not in classifer_params_id, params_to_update)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"630a2526100e5221100474f753aaa53c94331084","scrolled":false},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(params_to_update)\n# optimizer = optim.SGD([\n#             {'params': conv_params},\n#             {'params': model.classifier.parameters(), 'lr': 1e-3}\n#             ], lr=1e-4, momentum=0.9)\n\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)\n\nbest_val_acc = 0.0\nbest_epoch = 0\nepoch_since_best = 0\n\nfor epoch in range(num_epochs):\n    scheduler.step()\n    model.train()\n    train_total_samples = 0\n    train_acc = 0\n    train_loss = 0\n    for i, data in enumerate(loader_train):\n        print('.',end='')\n        inputs, labels = data\n        train_total_samples += labels.size()[0]\n        if use_gpu:\n            inputs, labels = inputs.cuda(), labels.cuda()\n\n        optimizer.zero_grad()\n        outputs = model(inputs)        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_pred = torch.argmax(outputs.data, dim=1)        \n        train_acc += torch.sum(train_pred == labels.data)\n        train_loss += loss.item() * labels.size()[0]\n            \n    model.eval()\n    valid_total_samples = 0\n    valid_acc = 0\n    val_loss = 0\n    for _, data in enumerate(loader_valid):\n        inputs, labels = data\n        valid_total_samples += labels.size()[0]\n        if use_gpu:\n            inputs, labels = inputs.cuda(), labels.cuda()\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        valid_pred = torch.argmax(outputs.data, dim=1)        \n        valid_acc += torch.sum(valid_pred == labels.data)\n        val_loss += loss.item() * labels.size()[0]\n\n    train_acc = train_acc.cpu().numpy() / train_total_samples\n    valid_acc = valid_acc.cpu().numpy() / valid_total_samples\n    train_loss = train_loss / train_total_samples\n    val_loss = val_loss / valid_total_samples\n    \n    print()\n    print('[Epoch %d] train loss %.6f train acc %.6f  valid loss %.6f valid acc %.6f' % (\n        epoch, train_loss, train_acc, val_loss, valid_acc))\n\n    if valid_acc > best_val_acc:\n        best_val_acc = valid_acc\n        best_epoch = epoch\n        epoch_since_best = 0\n        print('save model...')\n        torch.save(model.state_dict(), 'tuned-resnet101.pt')\n        print('saved.')\n    else:\n        epoch_since_best += 1\n        \n    if epoch_since_best > early_stopping:\n        break\n            \nprint('Finished Training')\nprint('best_epoch: %d, best_val_acc %.6f' % (best_epoch, best_val_acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"18d04a69ca81499c0fc03036d85de63f054d28d4"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}